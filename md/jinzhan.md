# 进展：
* 自动化扩链已经能跑小规模数据了，但是在处理大规模数据时，太费时了
* 在url生成正则表达式这一步，修正了最长公共子串的匹配错误，让它从"http"开始匹配，避免匹配到中间较长的字符串
* 优化了寻找url列表的最长公共子串的函数，时间复杂度由O(N2)下降为O(N) 

## 难点：
1. 不同网站的路径层数不一样，需要设计出通用的路径层数获取方法
2. URL聚类模块运行时间太长，正在尝试多线程／多进程来解决

## 针对各个难点的解决idea:
### 1. 需要设计整合出三个模块：
* `泛化模块`：根据输入的URL生成泛化的正则表达式re_LIST。
    
* `测评模块`：统计各个站点所对应的re_LIST正则表达式在站中的覆盖率。
* `迭代模块`：设定一个通用层数范围，如3～7层，在此范围内迭代。具体迭代做法：针对每个站点，记录下不同层数所生成的re_LIST的覆盖率，取最高覆盖率对应的层数作为这个站点的默认层数。
    ```
        迭代模块要小心出现 '过拟合' 现象，比如出现 www\.baidu\.com/* 这种看似覆盖率很高，但是没有作用的正则表达式，这个问题也有待解决
    ```

### 2. 优化方面：
* 通过减少建树的层数，让建树的层数仅大于需求的层数一层，如需求层数为4层，就只建立五层的树，高于五层的部分不再分割。

* 不再把协议和域名加入建树的，针对每个域名都建一次树，在class里面定义一个self.domain来记录该树对应的域名，以及self.protocol来定义是http还是https

## 版本：
V2.0: `extract_pattern.py` 修复最长公共子串的匹配错误